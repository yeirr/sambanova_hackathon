#!/bin/bash
#vim:filetype=sh

VLLM_ATTENTION_BACKEND="FLASHINFER" vllm serve neuralmagic/Llama-3.2-1B-Instruct-quantized.w8a8 \
	--chat-template ./template_chatml.jinja \
	--dtype auto \
	--port 8001 \
	--gpu-memory-utilization 0.2 \
	--max-model-len 2048 \
	--max-seq-len-to-capture 2048 \
	--max-num-seqs 5 \
	--api-key token-abc123 \
	--disable-log-stats \
	--disable-log-requests \
	--use-v2-block-manager \
	--disable-sliding-window \
	--enable-prefix-caching
